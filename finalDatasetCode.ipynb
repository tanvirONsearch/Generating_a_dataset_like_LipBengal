{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import glob\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET FOLDERS AND SUBFOLDERS GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Loads words from text file of listed words separated by /n'''\n",
    "\n",
    "def load_words(pth : str) -> list[str]:\n",
    "    words=[]\n",
    "    with open(pth,'r',encoding='utf-8') as words_text:\n",
    "        for line in words_text:\n",
    "           indexed_words=line.strip().split('. ',1) #indexed_words is raw data with number\n",
    "           word=indexed_words[1]          #separating number and words\n",
    "           words.append(word)\n",
    "    return words # returns a useable words list from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Makes folders and subfolders from a parent folder's list and child folders list'''\n",
    "\n",
    "def make_folders(location:str,prt_list,chld_list): # (destination path ,parent directory , child directory)\n",
    "    for folder in prt_list:\n",
    "        try:\n",
    "            if not os.path.exists(os.path.join(location,str(folder))):\n",
    "                os.mkdir(os.path.join(location,str(folder)))\n",
    "            else:\n",
    "                print(f\"parent foldar already exist{os.path.join(location,str(folder))}\")\n",
    "\n",
    "\n",
    "            for ch_folder in chld_list:\n",
    "                    \n",
    "                try:\n",
    "                    if not os.path.exists(os.path.join(location,str(folder),str(ch_folder))):\n",
    "                        os.mkdir(os.path.join(location,str(folder),str(ch_folder)))\n",
    "                    else:\n",
    "                        print(f\"child foldar already exist{os.path.join(location,str(folder),str(ch_folder))}\")        \n",
    "                except:\n",
    "                    print(f\"invalid syntax in child{os.path.join(location,str(folder),str(ch_folder))}\")         \n",
    "\n",
    "        except:\n",
    "            print(f\"invalid syntax in parent{os.path.join(location,str(folder))}\")\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_speaker=150\n",
    "word_text_path= r'.\\Raw_Data\\uniquelist.txt' # path for file that contains words list\n",
    "datast_path=r'.\\Dataset' #path where we want to save the data set\n",
    "\n",
    "parent_folders=[f\"s{i}\" for i in range(1,total_speaker+1)] #generating parent folder ie. speaker folder s1,s2,s3,s4\n",
    "\n",
    "make_folders(datast_path,parent_folders,load_words('Raw_Data/uniquelist.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANNOTATION FILE PROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabs xl file from the given path\n",
    "def find_xl(pth):\n",
    "    all_files=os.listdir(pth)\n",
    "    xl = [file for file in all_files if file.endswith('.xlsx')]\n",
    "    xl_loc=os.path.join(pth,xl[0])\n",
    "    try:\n",
    "        #print(xl)\n",
    "        if len(xl)==1:\n",
    "            return xl_loc\n",
    "        else:\n",
    "            print(\"Too many xl\")\n",
    "            xl=[]\n",
    "    except:\n",
    "        print('no xl error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xl_vids(poth:str) -> list[str]:  #returns annotated vdo list from xl\n",
    "    df=pd.read_excel(poth)\n",
    "    col=[i for i in df.columns]\n",
    "    col=col[2:]\n",
    "    annotated_vids=[i for i in col if (df[i] == \"0::.,0::.\" ).sum()<50] # checks if there are more than 50 empty entry in the columns, if true discards it\n",
    "    try:\n",
    "        return annotated_vids\n",
    "    except:\n",
    "        print(\"no particular annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Converts 0:0:0.0 (H:Min:Sec.Ms) to milliseconds format for checking the annotation entry'''\n",
    "\n",
    "def tstr2ms(time_string):\n",
    "    # Split the time string into hours, minutes, seconds, and milliseconds\n",
    "    time_parts = time_string.split(':')\n",
    "\n",
    "    # Convert hours, minutes, seconds, and milliseconds to integers (use 0 if missing)\n",
    "    hours = int(time_parts[0]) if len(time_parts) > 0 and time_parts[1]!=\"\" else 0\n",
    "    minutes = int(time_parts[1]) if len(time_parts) > 1 and time_parts[1]!=\"\" else 0\n",
    "    seconds_parts = time_parts[2].split('.')\n",
    "    seconds = int(seconds_parts[0]) if len(seconds_parts)> 0 and seconds_parts[0]!=\"\"  else 0\n",
    "    if len(str(seconds_parts[1]))<2:\n",
    "           milliseconds = (int(seconds_parts[1])*100)  if len(seconds_parts) > 1 and seconds_parts[1]!=\"\" else 0\n",
    "           #print(\"in the one digit range\")\n",
    "    elif len(str(seconds_parts[1]))<3:\n",
    "         milliseconds = (int(seconds_parts[1])*10)  if len(seconds_parts) > 1 and seconds_parts[1]!=\"\" else 0\n",
    "         #print(\"in the two digit range\")\n",
    "    else:\n",
    "        milliseconds = int(seconds_parts[1]) if len(seconds_parts) > 1 and seconds_parts[1]!=\"\" else 0\n",
    "        #print(\"in the three digit range\")\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate total milliseconds\n",
    "    total_milliseconds = (\n",
    "        hours * 60 * 60 * 1000 +\n",
    "        minutes * 60 * 1000 +\n",
    "        seconds * 1000 +\n",
    "        milliseconds\n",
    "    )\n",
    "\n",
    "    return total_milliseconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   Checks if annotation entries are valid or not and returns start and ending time of words of a particular speaker'''\n",
    "\n",
    "def chk_annotation(vdi:str)->list[int]:\n",
    "    annt=[a for a in df[vdi]]\n",
    "    #print(annt)\n",
    "    stym=[]\n",
    "    etym=[]\n",
    "    \n",
    "    for k,val in enumerate(annt):\n",
    "        try:\n",
    "         stym.append(tstr2ms(val.split(\",\")[0])) \n",
    "         etym.append(tstr2ms(val.split(\",\")[1]))\n",
    "         #stym.append(val.split(\",\")[0]) #uncomment for movie pie\n",
    "         #etym.append(val.split(\",\")[1])\n",
    "         if tstr2ms(val.split(\",\")[0])>tstr2ms(val.split(\",\")[1]):\n",
    "            print(f\"error:STRT-TIME > END-TIME in index {k+1}\")\n",
    "         if abs(tstr2ms(val.split(\",\")[0])-tstr2ms(val.split(\",\")[1]))<200:\n",
    "            print(f\"error:less than 200ms for word in index {k+1}\")\n",
    "         if abs(tstr2ms(val.split(\",\")[0])-tstr2ms(val.split(\",\")[1]))>3000:\n",
    "            print(f\"error:more than 3 sec for word in index {k+1}\")\n",
    "        \n",
    "        except:\n",
    "           print(f\"error:format doesn't match in index {k+1}\")   \n",
    "      \n",
    "    return stym,etym\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIDEO PROCESSING FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SAVES IMAGE FRAMES TO DESTANTION IN VERBOSE MODE'''\n",
    "def save_frame(frame_info):\n",
    "    frame_count, frame, frame_filename, output_folder = frame_info\n",
    "    cv2.imwrite(frame_filename, frame, [cv2.IMWRITE_PNG_COMPRESSION, 5])\n",
    "    shutil.move(frame_filename, output_folder)\n",
    "    \n",
    "    print(f\"Frame {frame_count} saved to {output_folder}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CROPING IMAGE PROCESSING FUNCTION RETURNS INFORMATION ABOT A FRAME TO SAVE'''\n",
    "def save_frames(video_path, output_folder, start_time, end_time):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if the video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Get frames per second (fps)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # Calculate start and end frame indices\n",
    "    start_frame = int(start_time/1000 * fps)\n",
    "    end_frame = int(end_time/1000 * fps)\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Set the video capture position to the start frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    # Read and save frames within the specified range\n",
    "    frame_count = start_frame\n",
    "    i = 1\n",
    "    _ = [os.remove(file) for file in glob.glob(os.path.join(r\"D:\\Dataset\\buffer\", '*.png'))]\n",
    "\n",
    "    frames_info = []\n",
    "\n",
    "    while frame_count <= end_frame:\n",
    "        ret, frame = cap.read()\n",
    "        #get the width and height\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        if not ret:\n",
    "            print(f\"Error: Could not read frame {frame_count}.\")\n",
    "            break\n",
    "\n",
    "        # Save the frame as an image in the output folder\n",
    "        frame_filename = os.path.join(r\"D:\\Dataset\\buffer\", f\"{i:02d}.png\")\n",
    "        if width != 1280 and height != 720:\n",
    "            frame = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        frames_info.append((frame_count, frame.copy(), frame_filename, output_folder))  # Use copy to avoid shared memory issues\n",
    "\n",
    "        frame_count += 1\n",
    "        i += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        executor.map(save_frame, frames_info)\n",
    "\n",
    "    return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP1: Find XL location and read the XL and find available annotated videos\n",
    "\n",
    "STEP2: Check the annotations\n",
    "\n",
    "\n",
    "STEP3: Make input and output folders\n",
    "\n",
    "\n",
    "STEP4: RUN THE LOOP BOX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Raw_data_Path = r'.\\Raw_Data'\n",
    "xl_path=find_xl(Raw_data_Path)\n",
    "df=pd.read_excel(xl_path)\n",
    "avialable = read_xl_vids(xl_path) ## available is the list of available annotated colums which has less than 50 missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_name=\"s7.mp4\"  ## put the names from the available list\n",
    "stym,etym=chk_annotation(vid_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_path= os.path.join(Raw_data_Path,vid_name)  #videos from base location\n",
    "output_path=r'.\\Dataset' #path where you want to save the dataset\n",
    "speaker_folder='s1'      #name of the speakr folder where you want to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i,word in enumerate(df['words']):\n",
    "    output_folder=os.path.join(output_path,speaker_folder,word)\n",
    "    start_time=stym[i]\n",
    "    end_time=etym[i]\n",
    "    if not start_time==end_time: ## checks if entry is empty or not\n",
    "       save_frames(video_path, output_folder, start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_path = '.\\\\Dataset\\\\s132'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Removes subfolders which have less than 5 frames and more than 45 frames'''\n",
    "for f in os.listdir():\n",
    "    if len(os.listdir(os.path.join(speaker_path,f)))<5:\n",
    "        os.rmdir(os.path.join(speaker_path,f))\n",
    "        print(f\"removed : {f}\")\n",
    "        \n",
    "    if len(os.listdir(os.path.join(speaker_path,f)))>45:\n",
    "        os.rmdir(os.path.join(speaker_path,f))\n",
    "        print(f\"removed : {f}\")\n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
